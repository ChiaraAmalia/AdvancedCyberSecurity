{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad effettuare il clustering con KMEANS per il dataframe contenente tutti i file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/scaled_total_document.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminazione duplicati\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di elementi per ogni label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una frazione casuale delle righe in base a una colonna specifica\n",
    "# Selezioniamo il 50% delle righe\n",
    "\n",
    "colonna_interessata = 'Label'\n",
    "frazione_da_selezionare = 0.5  # Ad esempio, seleziona il 50% delle righe\n",
    "\n",
    "\n",
    "df = df.groupby(colonna_interessata).apply(lambda x: x.sample(frac=frazione_da_selezionare, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di elementi per ogni label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendiamo due feature alla volta\n",
    "\n",
    "feature_1 = ''\n",
    "feature_2 = ''\n",
    "\n",
    "\n",
    "df = df[[feature_1, feature_2,'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign = df[df.Label == 1]\n",
    "benign = df[df.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(malign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([malign, benign.sample(len(malign))])\n",
    "bal_x = balanced_d.iloc[:,:-1]\n",
    "bal_y = balanced_d.iloc[:,-1:]\n",
    "balanced_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(balanced_d['Label'].unique())  # numero di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo il clustering con Kmeans\n",
    "\n",
    "km = KMeans(n_clusters=n_clusters)\n",
    "y_pred = km.fit_predict(bal_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = bal_x[y_pred == i]\n",
    "    cluster_classes = bal_y[y_pred == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dei risultati\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "scatter = axs.scatter(bal_x[feature_1], bal_x[feature_2], c=y_pred)\n",
    "scatter\n",
    "axs.set_title(\"K-means\")\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centroid')\n",
    "\n",
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    axs.text(\n",
    "        np.mean(bal_x[feature_1][y_pred == i]), np.mean(bal_x[feature_2][y_pred == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "title = (\"K-means \" + str(feature_1) + \" \" + str(feature_2))\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/clustering_totale/'):\n",
    "    os.makedirs('image/clustering_totale/')\n",
    "plt.savefig('image/clustering_totale/'+str(feature_name)+'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_pred))\n",
    "    if y_pred[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_pred[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_kmeans = str(accuracy_score(y_pred,bal_y))\n",
    "precision_kmeans = str(precision_score(y_pred,bal_y))\n",
    "recall_kmeans = str(recall_score(y_pred,bal_y))\n",
    "\n",
    "# accuratezza kmeans\n",
    "print(\"accuratezza\" + accuracy_kmeans)\n",
    "# precision kmeans\n",
    "print(\"precision\" + precision_kmeans)\n",
    "# recall kemans\n",
    "print(\"recall\" + recall_kmeans)\n",
    "\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_kmeans,precision_kmeans,recall_kmeans]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'):\n",
    "    os.makedirs('metriche/')\n",
    "\n",
    "metriche.to_csv('metriche/metriche_kmeans_totale.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
