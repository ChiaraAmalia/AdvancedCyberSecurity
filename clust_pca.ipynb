{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad applicare algoritmi di clustering dopo aver eliminato eventuali duplicati ed aver ridotto le dimensioni del dataset con undersampling. Prima di applicare gli algoritmi di clustering, applichiamo la pca che ci permette di selezionare le feature pi√π rilevanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_file='Friday-02-03-2018_TrafficForML_CICFlowMeter'\n",
    "\n",
    "with open('pickle/'+nome_file+'/scaled_document.pickle', 'rb') as handle:\n",
    "\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una frazione casuale delle righe in base a una colonna specifica\n",
    "# Selezioniamo il 50% delle righe\n",
    "\n",
    "colonna_interessata = 'Label'\n",
    "frazione_da_selezionare = 0.5  # Ad esempio, seleziona il 50% delle righe\n",
    "\n",
    "\n",
    "df = df.groupby(colonna_interessata).apply(lambda x: x.sample(frac=frazione_da_selezionare, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di feature per label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = df[df.Label == 1]\n",
    "benign = df[df.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([bot, benign.sample(len(bot))])\n",
    "balanced_d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicazione della PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver=\"auto\").fit(balanced_d)\n",
    "pca_x = pca.transform(balanced_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applicazione del kmeans\n",
    "kmeans = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "ymeans = kmeans.fit_predict(pca_x)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster of PCAs', fontsize = 30)\n",
    "\n",
    "plt.scatter(pca_x[ymeans == 0, 0], pca_x[ymeans == 0, 1], s = 100, c = 'pink')\n",
    "plt.scatter(pca_x[ymeans == 1, 0], pca_x[ymeans == 1, 1], s = 100, c = 'green')\n",
    "\n",
    "centers = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], s = 50, c = 'black', label=\"center\")\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individuazione eps\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(pca_x)\n",
    "distances, indices = nbrs.kneighbors(pca_x)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(distances[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applicazione DBSCAN\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=1, min_samples=6).fit(pca_x)\n",
    "ymeans = db.labels_\n",
    "ymeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster of PCAs', fontsize = 30)\n",
    "\n",
    "plt.scatter(pca_x[ymeans == -1, 0], pca_x[ymeans == -1, 1], s = 100, c = 'black')\n",
    "plt.scatter(pca_x[ymeans == 0, 0], pca_x[ymeans == 0, 1], s = 100, c = 'pink')\n",
    "plt.scatter(pca_x[ymeans == 1, 0], pca_x[ymeans == 1, 1], s = 100, c = 'green')\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
