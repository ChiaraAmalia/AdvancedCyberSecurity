{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     True_value\n",
      "0             0\n",
      "1             0\n",
      "2             0\n",
      "3             0\n",
      "4             0\n",
      "..          ...\n",
      "145           2\n",
      "146           2\n",
      "147           2\n",
      "148           2\n",
      "149           2\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "df_x = pd.DataFrame(X, columns = ['F1','F2','F3','F4'])\n",
    "df_y = pd.DataFrame(y, columns = ['True_value'])\n",
    "print(df_x.shape)\n",
    "print(type(df_x))\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(df_x, df_y['True_value'])\n",
    "#print(clf.feature_importances_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input_Features   F_Score\n",
      "2             F3  0.424556\n",
      "3             F4  0.420308\n",
      "0             F1  0.097335\n",
      "1             F2  0.057801\n"
     ]
    }
   ],
   "source": [
    "features_score = pd.DataFrame(clf.feature_importances_)\n",
    "features = pd.DataFrame(df_x.columns)\n",
    "feature_score = pd.concat([features,features_score],axis=1)\n",
    "# Assigning column names\n",
    "feature_score.columns = [\"Input_Features\",\"F_Score\"]\n",
    "print(feature_score.nlargest(10,columns=\"F_Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodo basato su SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False,max_iter=2000)\n",
    "lsvc = lsvc.fit(df_x, df_y['True_value'])\n",
    "model_2 = SelectFromModel(lsvc, prefit=True)\n",
    "X_new_2 = model_2.transform(X)\n",
    "X_new_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'features_score_svm = pd.DataFrame(lsvc.feature_names_in_)\\nfeatures_svm = pd.DataFrame(df_x.columns)\\nfeature_score_svm = pd.concat([features_svm,features_score_svm],axis=1)\\n# Assigning column names\\nfeatures_score_svm.columns = [\"Input_Features\",\"F_Score\"]\\nprint(feature_score_svm.nlargest(10,columns=\"F_Score\"))'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''features_score_svm = pd.DataFrame(lsvc.feature_names_in_)\n",
    "features_svm = pd.DataFrame(df_x.columns)\n",
    "feature_score_svm = pd.concat([features_svm,features_score_svm],axis=1)\n",
    "# Assigning column names\n",
    "features_score_svm.columns = [\"Input_Features\",\"F_Score\"]\n",
    "print(feature_score_svm.nlargest(10,columns=\"F_Score\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "features_names = df_x.head(0)\n",
    "svm = svm.SVC(kernel='linear',max_iter=500)\n",
    "svm.fit(df_x, df_y['True_value'])\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False,max_iter=2000)\n",
    "lsvc = lsvc.fit(df_x, df_y['True_value'])\n",
    "\n",
    "f_importances(abs(svm.coef_[1]), features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pc\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.41803783,  0.96627493, -2.52149409, -1.08399852],\n",
       "       [ 0.53096505, -0.31441687, -0.19911417, -0.94921552],\n",
       "       [-0.11292721, -0.65185806,  2.72060826,  2.03321404]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selector = SelectFromModel(estimator=LogisticRegression()).fit(df_x, df_y)\n",
    "selector.estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=DecisionTreeClassifier(), n_features_to_select=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=DecisionTreeClassifier(), n_features_to_select=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=DecisionTreeClassifier(), n_features_to_select=3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define the method\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=3)\n",
    "# fit the model\n",
    "rfe.fit(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.886 (0.034)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate RFE for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of informative, redundant and repeated features must sum to less than the number of total features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVR\n\u001b[0;32m      6\u001b[0m \u001b[39m# define dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[39m=\u001b[39m make_classification(n_samples\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, n_features\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, n_informative\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, n_redundant\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# define RFE\u001b[39;00m\n\u001b[0;32m      9\u001b[0m rfe \u001b[39m=\u001b[39m RFE(estimator\u001b[39m=\u001b[39mSVR(), n_features_to_select\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pc\\anaconda3\\envs\\tensor\\lib\\site-packages\\sklearn\\datasets\\_samples_generator.py:178\u001b[0m, in \u001b[0;36mmake_classification\u001b[1;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m# Count features, clusters and samples\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m n_informative \u001b[39m+\u001b[39m n_redundant \u001b[39m+\u001b[39m n_repeated \u001b[39m>\u001b[39m n_features:\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of informative, redundant and repeated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfeatures must sum to less than the number of total\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m \u001b[39m# Use log2 to avoid overflow errors\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m n_informative \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39mlog2(n_classes \u001b[39m*\u001b[39m n_clusters_per_class):\n",
      "\u001b[1;31mValueError\u001b[0m: Number of informative, redundant and repeated features must sum to less than the number of total features"
     ]
    }
   ],
   "source": [
    "# report which features were selected by RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define RFE\n",
    "rfe = RFE(estimator=SVR(), n_features_to_select=5)\n",
    "# fit RFE\n",
    "rfe.fit(df_x, df_y)\n",
    "# summarize all features\n",
    "for i in range(4):\n",
    " print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
