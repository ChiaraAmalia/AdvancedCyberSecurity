{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad applicare la PCA per il dataset totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib.lines import Line2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/scaled_total_document.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminazione duplicati\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una frazione casuale delle righe in base a una colonna specifica\n",
    "# Selezioniamo il 50% delle righe\n",
    "\n",
    "colonna_interessata = 'Label'\n",
    "frazione_da_selezionare = 0.5  # Ad esempio, seleziona il 50% delle righe\n",
    "\n",
    "\n",
    "df = df.groupby(colonna_interessata).apply(lambda x: x.sample(frac=frazione_da_selezionare, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di feature per label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo un array in cui andiamo a mettere le 5 feature più importanti per filtrare poi il dataframe\n",
    "\n",
    "import csv\n",
    "\n",
    "results = []\n",
    "with open('top_feature/top5_totale.csv', newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append(row[0])\n",
    "\n",
    "results.pop(0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otteniamo il dataframe con solo le 5 feature più importanti\n",
    "\n",
    "df_filtrato = pd.DataFrame()\n",
    "for a in df.head(0):\n",
    "    if a in results:\n",
    "        df_filtrato[a] = df[a]\n",
    "\n",
    "df_filtrato['Label'] = df['Label']\n",
    "display(df_filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign = df_filtrato[df_filtrato.Label == 1]\n",
    "benign = df_filtrato[df_filtrato.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(malign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([malign, benign.sample(len(malign))])\n",
    "bal_x = balanced_d.iloc[:,:-1]\n",
    "bal_y = balanced_d.iloc[:,-1:]\n",
    "balanced_d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicazione della PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver=\"auto\").fit(bal_x)\n",
    "pca_x = pca.transform(bal_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(balanced_d['Label'].unique())  # numero di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applicazione del kmeans\n",
    "km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "y_pred = km.fit_predict(pca_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = pca_x[y_pred == i]\n",
    "    cluster_classes = bal_y[y_pred == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dei risultati\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster of PCAs K-means', fontsize = 30)\n",
    "\n",
    "plt.scatter(pca_x[y_pred == 0, 0], pca_x[y_pred == 0, 1], s = 100, c = 'purple')\n",
    "plt.scatter(pca_x[y_pred == 1, 0], pca_x[y_pred == 1, 1], s = 100, c = 'yellow')\n",
    "\n",
    "centers = pca.transform(km.cluster_centers_)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], s = 50, c = 'black', label=\"center\")\n",
    "\n",
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend()\n",
    "\n",
    "title = \"KMeans_PCA\"\n",
    "if not os.path.exists('image/clustering_totale/'):\n",
    "    os.makedirs('image/clustering_totale/')\n",
    "plt.savefig('image/clustering_totale/'+ title +'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_pred))\n",
    "    if y_pred[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_pred[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_kmeans = str(accuracy_score(y_pred,bal_y))\n",
    "precision_kmeans = str(precision_score(y_pred,bal_y))\n",
    "recall_kmeans = str(recall_score(y_pred,bal_y))\n",
    "\n",
    "# accuratezza kmeans\n",
    "print(\"accuratezza\" + accuracy_kmeans)\n",
    "# precision kmeans\n",
    "print(\"precision\" + precision_kmeans)\n",
    "# recall kemans\n",
    "print(\"recall\" + recall_kmeans)\n",
    "\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_kmeans,precision_kmeans,recall_kmeans]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'):\n",
    "    os.makedirs('metriche/')\n",
    "\n",
    "metriche.to_csv('metriche/metriche_kmeans_pca_totale.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
