{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad applicare algoritmi di clustering dopo aver eliminato eventuali duplicati ed aver ridotto le dimensioni del dataset con undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_file='Friday-02-03-2018_TrafficForML_CICFlowMeter'\n",
    "\n",
    "with open('pickle/'+nome_file+'/scaled_document.pickle', 'rb') as handle:\n",
    "\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminazione duplicati\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di elementi per ogni label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una frazione casuale delle righe in base a una colonna specifica\n",
    "# Selezioniamo il 50% delle righe\n",
    "\n",
    "colonna_interessata = 'Label'\n",
    "frazione_da_selezionare = 0.5  # Ad esempio, seleziona il 50% delle righe\n",
    "\n",
    "\n",
    "df = df.groupby(colonna_interessata).apply(lambda x: x.sample(frac=frazione_da_selezionare, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di elementi per ogni label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendiamo due feature alla volta\n",
    "\n",
    "feature_1 = 'Init Bwd Win Byts'\n",
    "feature_2 = 'Fwd Pkts/s'\n",
    "\n",
    "\n",
    "df = df[[feature_1, feature_2,'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = df[df.Label == 1]\n",
    "benign = df[df.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([bot, benign.sample(len(bot))])\n",
    "bal_x = balanced_d.iloc[:,:-1]\n",
    "bal_y = balanced_d.iloc[:,-1:]\n",
    "balanced_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(balanced_d['Label'].unique())  # numero di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo il clustering con Kmeans\n",
    "\n",
    "km = KMeans(n_clusters=n_clusters)\n",
    "y_pred = km.fit_predict(bal_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = bal_x[y_pred == i]\n",
    "    cluster_classes = bal_y[y_pred == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dei risultati\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "scatter = axs.scatter(bal_x[feature_1], bal_x[feature_2], c=y_pred)\n",
    "scatter\n",
    "axs.set_title(\"K-means\")\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centroid')\n",
    "\n",
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    axs.text(\n",
    "        np.mean(bal_x[feature_1][y_pred == i]), np.mean(bal_x[feature_2][y_pred == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "title = (\"K-means \" + str(feature_1) + \" \" + str(feature_2))\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/'+nome_file+'/clustering/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering/')\n",
    "plt.savefig('image/'+nome_file+'/clustering/'+str(feature_name)+'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_pred))\n",
    "    if y_pred[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_pred[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_kmeans = str(accuracy_score(y_pred,bal_y))\n",
    "precision_kmeans = str(precision_score(y_pred,bal_y))\n",
    "recall_kmeans = str(recall_score(y_pred,bal_y))\n",
    "\n",
    "# accuratezza kmeans\n",
    "print(\"accuratezza\" + accuracy_kmeans)\n",
    "# precision kmeans\n",
    "print(\"precision\" + precision_kmeans)\n",
    "# recall kemans\n",
    "print(\"recall\" + recall_kmeans)\n",
    "\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_kmeans,precision_kmeans,recall_kmeans]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering'+'/metriche_kmeans.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering gerarchico\n",
    "\n",
    "hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
    "y_hc = hc.fit_predict(bal_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = bal_x[y_hc == i]\n",
    "    cluster_classes = bal_y[y_hc == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(bal_x.iloc[:, 0], bal_x.iloc[:, 1], c=y_hc)\n",
    "\n",
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    plt.text(\n",
    "        np.mean(bal_x[feature_1][y_hc == i]), np.mean(bal_x[feature_2][y_hc == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "plt.title('Hierarchial Clustering', fontsize = 20)\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "\n",
    "title = (\"Clust_gerarchico \" + str(feature_1) + \" \" + str(feature_2))\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/'+nome_file+'/clustering/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering/')\n",
    "plt.savefig('image/'+nome_file+'/clustering/'+str(feature_name)+'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_hc))\n",
    "    if y_hc[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_hc[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gerarchico = str(accuracy_score(y_hc,bal_y))\n",
    "precision_gerarchico = str(precision_score(y_hc,bal_y))\n",
    "recall_gerarchico = str(recall_score(y_hc,bal_y))\n",
    "\n",
    "# accuratezza gerarchico\n",
    "print(\"accuratezza\" + accuracy_gerarchico)\n",
    "# precision gerarchico\n",
    "print(\"precision\" + precision_gerarchico)\n",
    "# recall gerarchico\n",
    "print(\"recall\" + recall_gerarchico)\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_gerarchico,precision_gerarchico,recall_gerarchico]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering'+'/metriche_gerarchico.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individuazione dell'eps migliore\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "values = bal_x.values\n",
    "neigh = NearestNeighbors(n_neighbors=5, n_jobs=4, algorithm='ball_tree', leaf_size=5)\n",
    "nbrs = neigh.fit(values)\n",
    "distances, indices = nbrs.kneighbors(values)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(distances[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicazione algoritmo dbscan\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.01, min_samples=6).fit(values)\n",
    "y_scan = db.labels_\n",
    "y_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = bal_x[y_scan == i]\n",
    "    cluster_classes = bal_y[y_scan == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster DBSCAN', fontsize = 30)\n",
    "\n",
    "plt.scatter(values[y_scan == -1, 0], values[y_scan == -1, 1], s = 100, c = 'black')\n",
    "plt.scatter(values[y_scan == 0, 0], values[y_scan == 0, 1], s = 100, c = 'pink')\n",
    "plt.scatter(values[y_scan == 1, 0], values[y_scan == 1, 1], s = 100, c = 'green')\n",
    "\n",
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    plt.text(\n",
    "        np.mean(bal_x[feature_1][y_scan == i]), np.mean(bal_x[feature_2][y_scan == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "\n",
    "title = (\"DB_Scan \" + str(feature_1) + \" \" + str(feature_2))\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/'+nome_file+'/clustering/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering/')\n",
    "plt.savefig('image/'+nome_file+'/clustering/'+str(feature_name)+'.png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_scan))\n",
    "    if y_scan[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_scan[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dbscan = str(accuracy_score(y_scan,bal_y))\n",
    "precision_dbscan = str(precision_score(y_scan,bal_y))\n",
    "recall_dbscan = str(recall_score(y_scan,bal_y))\n",
    "\n",
    "# accuratezza dbscan\n",
    "print(\"accuratezza\" + accuracy_dbscan)\n",
    "# precision dbscan\n",
    "print(\"precision\" + precision_dbscan)\n",
    "# recall dbscan\n",
    "print(\"recall\" + recall_dbscan)\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_dbscan,precision_dbscan,recall_dbscan]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering'+'/metriche_dbscan.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering SOM\n",
    "y_som = SOM(m=1, n=2, dim=2)\n",
    "\n",
    "y_som.fit(bal_x.values)\n",
    "\n",
    "predictions = y_pred.predict(bal_x.values)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = bal_x[predictions == i]\n",
    "    cluster_classes = bal_y[predictions == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "print(bal_y['Label'].unique())\n",
    "print(type(y_pred))\n",
    "print(np.unique(predictions))\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "axs.scatter(bal_x[feature_1], bal_x[feature_2], c=predictions)\n",
    "axs.set_title(\"Mixture of Gaussian Blobs\")\n",
    "\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    axs.text(\n",
    "        np.mean(bal_x[feature_1][predictions == i]), np.mean(bal_x[feature_2][predictions == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "plt.title('SOM ', fontsize = 20)\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "\n",
    "title = (\"SOM \" + str(feature_1) + \" - \" + str(feature_2))\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/'+nome_file+'/clustering/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering/')\n",
    "plt.savefig('image/'+nome_file+'/clustering/'+str(feature_name)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(predictions))\n",
    "    if predictions[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        predictions[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_som = str(accuracy_score(predictions,bal_y))\n",
    "precision_som = str(precision_score(predictions,bal_y))\n",
    "recall_som = str(recall_score(predictions,bal_y))\n",
    "\n",
    "# accuratezza gerarchico\n",
    "print(\"accuratezza \" + accuracy_som)\n",
    "# precision gerarchico\n",
    "print(\"precision \" + precision_som)\n",
    "# recall gerarchico\n",
    "print(\"recall \" + recall_som)\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_som,precision_som,recall_som]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file+ '/clustering/'):\n",
    "    os.makedirs('metriche/'+nome_file+ '/clustering/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file+ '/clustering' + '/metriche_som.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
