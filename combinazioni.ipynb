{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie\n",
    "\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili globali\n",
    "\n",
    "mypath = 'dataset'\n",
    "\n",
    "# Mi vado a prendere i path di tutti i file nella cartella dataset\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Mi vado a generare tutte le possibili combinazioni di due elementi da un insieme di 5 elementi\n",
    "\n",
    "\n",
    "comb = list(combinations(range(0,5), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv', 'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv', 'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv', 'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv', 'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv', 'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv', 'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv', 'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv', 'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv', 'Friday-23-02-2018_TrafficForML_CICFlowMeter.csv']\n"
     ]
    }
   ],
   "source": [
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document = 'Wednesday-28-02-2018_TrafficForML_CICFlowMeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a pulire tutti i dataset\n",
    "\n",
    "# Come prima cosa andiamo a leggere le feature dai vari file csv\n",
    "\n",
    "anova = pd.read_csv('top_feature/'+document+\"/anova.csv\")\n",
    "tree = pd.read_csv('top_feature/'+document+\"/ExtraTree.csv\")\n",
    "svm = pd.read_csv('top_feature/'+document+\"/SVM.csv\")\n",
    "rfe = pd.read_csv('top_feature/'+document+\"/RFE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a normalizzare tutti gli score delle feature, in maniera tale da avere valori compresi tra 0 e 1\n",
    "\n",
    "anova['F_Score'] = anova['F_Score']/anova['F_Score'].max()\n",
    "tree['F_Score'] = tree['F_Score']/tree['F_Score'].max()\n",
    "svm['F_Score'] = svm['F_Score']/svm['F_Score'].max()\n",
    "rfe['F_Score'] = rfe['F_Score']/rfe['F_Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_Score</th>\n",
       "      <th>Input_Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Init Bwd Win Byts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.706251</td>\n",
       "      <td>Flow IAT Std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641805</td>\n",
       "      <td>Bwd Pkt Len Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640393</td>\n",
       "      <td>Pkt Len Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562364</td>\n",
       "      <td>Fwd IAT Std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.485466</td>\n",
       "      <td>Flow IAT Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.480161</td>\n",
       "      <td>Bwd Seg Size Avg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.480161</td>\n",
       "      <td>Bwd Pkt Len Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.437510</td>\n",
       "      <td>Fwd IAT Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.418868</td>\n",
       "      <td>Pkt Len Mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_Score     Input_Features\n",
       "0  1.000000  Init Bwd Win Byts\n",
       "1  0.706251       Flow IAT Std\n",
       "2  0.641805    Bwd Pkt Len Max\n",
       "3  0.640393        Pkt Len Max\n",
       "4  0.562364        Fwd IAT Std\n",
       "5  0.485466      Flow IAT Mean\n",
       "6  0.480161   Bwd Seg Size Avg\n",
       "7  0.480161   Bwd Pkt Len Mean\n",
       "8  0.437510       Fwd IAT Mean\n",
       "9  0.418868       Pkt Len Mean"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo una concatenazione dei vari dataframe.\n",
    "# Saranno utilizzati per prendere le feature che si ripetono di più e che hanno i punteggi maggiori\n",
    "\n",
    "total_feature = pd.concat([anova,tree,svm,rfe],ignore_index=True)\n",
    "total_feature_count = pd.concat([anova,tree,svm,rfe],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "9       Flow IAT Mean      3\n",
      "11        Flow Pkts/s      3\n",
      "0         Bwd IAT Tot      2\n",
      "21  Init Fwd Win Byts      2\n",
      "20  Init Bwd Win Byts      2\n",
      "17         Fwd Pkts/s      2\n",
      "13        Fwd IAT Std      2\n",
      "10       Flow IAT Std      2\n",
      "12       Fwd IAT Mean      2\n",
      "8        Flow IAT Max      2\n",
      "7       Flow Duration      2\n",
      "6         Flow Byts/s      2\n",
      "3          Bwd Pkts/s      2\n",
      "1     Bwd Pkt Len Max      1\n",
      "5      CWE Flag Count      1\n",
      "14        Fwd IAT Tot      1\n",
      "15    Fwd Pkt Len Max      1\n",
      "16   Fwd Pkt Len Mean      1\n",
      "4    Bwd Seg Size Avg      1\n",
      "18   Fwd Seg Size Avg      1\n",
      "19      Fwd URG Flags      1\n",
      "2    Bwd Pkt Len Mean      1\n",
      "22        Pkt Len Max      1\n",
      "23       Pkt Len Mean      1\n",
      "24       Pkt Size Avg      1\n"
     ]
    }
   ],
   "source": [
    "# Andiamo a eseguire un operazione di group by, con successivo count delle occorrenze dei vari campi\n",
    "\n",
    "total_feature_count = total_feature_count.groupby(['Input_Features']).count().reset_index().sort_values(by='F_Score',ascending=False)\n",
    "\n",
    "# Andiamo a rinominare la colonna F_Score, che adesso contiene i valori di count\n",
    "\n",
    "total_feature_count.rename(columns = {'F_Score':'Conto'}, inplace = True)\n",
    "print(total_feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "9       Flow IAT Mean      3\n",
      "11        Flow Pkts/s      3\n",
      "0         Bwd IAT Tot      2\n",
      "21  Init Fwd Win Byts      2\n",
      "20  Init Bwd Win Byts      2\n",
      "17         Fwd Pkts/s      2\n",
      "13        Fwd IAT Std      2\n",
      "10       Flow IAT Std      2\n",
      "12       Fwd IAT Mean      2\n",
      "8        Flow IAT Max      2\n"
     ]
    }
   ],
   "source": [
    "# Delle delle feature più frequenti mi interessano le prime dieci\n",
    "\n",
    "most_frequent = total_feature_count[:10]\n",
    "\n",
    "print(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features   F_Score\n",
      "18      Flow IAT Mean  0.715298\n",
      "25      Flow IAT Mean  0.485466\n",
      "36      Flow IAT Mean  1.000000\n",
      "1         Flow Pkts/s  0.459988\n",
      "10        Flow Pkts/s  1.000000\n",
      "35        Flow Pkts/s  1.000000\n",
      "19        Bwd IAT Tot  0.683407\n",
      "31        Bwd IAT Tot  1.000000\n",
      "6   Init Fwd Win Byts  0.144963\n",
      "13  Init Fwd Win Byts  0.886946\n",
      "2   Init Bwd Win Byts  0.246871\n",
      "20  Init Bwd Win Byts  1.000000\n",
      "3          Fwd Pkts/s  0.160852\n",
      "12         Fwd Pkts/s  0.965384\n",
      "24        Fwd IAT Std  0.562364\n",
      "34        Fwd IAT Std  1.000000\n",
      "21       Flow IAT Std  0.706251\n",
      "37       Flow IAT Std  1.000000\n",
      "28       Fwd IAT Mean  0.437510\n",
      "30       Fwd IAT Mean  1.000000\n",
      "11       Flow IAT Max  0.989897\n",
      "38       Flow IAT Max  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Ci serve ancora il parametro F_Scores, quindi creiamo un nuovo dataframe con queste righe.\n",
    "# Abbiamo le dieci righe, però, sono ancora presenti le ridondanze che prima avevamo eliminato.\n",
    "\n",
    "test = pd.DataFrame(data=[],columns=total_feature.columns)\n",
    "\n",
    "for a in most_frequent['Input_Features']:\n",
    "    test = pd.concat([test,total_feature[total_feature['Input_Features'] == a]])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una variabile all'interno del quale vado a salvare il groupby del precedente dataframe, solo che in uesto caso\n",
    "# andiamo a sommare i punteggi di F_Scores, invece di contare le occorrenze.\n",
    "\n",
    "group_by = test.groupby(['Input_Features'])['F_Score'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "0        Bwd IAT Tot  1.683407\n",
      "1       Flow IAT Max  1.989897\n",
      "2      Flow IAT Mean  2.200764\n",
      "3       Flow IAT Std  1.706251\n",
      "4        Flow Pkts/s  2.459988\n",
      "5       Fwd IAT Mean  1.437510\n",
      "6        Fwd IAT Std  1.562364\n",
      "7         Fwd Pkts/s  1.126236\n",
      "8  Init Bwd Win Byts  1.246871\n",
      "9  Init Fwd Win Byts  1.031909\n"
     ]
    }
   ],
   "source": [
    "print(group_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "4        Flow Pkts/s  2.459988\n",
      "2      Flow IAT Mean  2.200764\n",
      "1       Flow IAT Max  1.989897\n",
      "3       Flow IAT Std  1.706251\n",
      "0        Bwd IAT Tot  1.683407\n",
      "6        Fwd IAT Std  1.562364\n",
      "5       Fwd IAT Mean  1.437510\n",
      "8  Init Bwd Win Byts  1.246871\n",
      "7         Fwd Pkts/s  1.126236\n",
      "9  Init Fwd Win Byts  1.031909\n"
     ]
    }
   ],
   "source": [
    "# Facciamo un ordinamento del dataframe precedente\n",
    "\n",
    "print(group_by.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A questo punto, terminiamo l'operazione andando a moltiplicare la frequenza per la somma dei punteggi delle varie feature.\n",
    "\n",
    "last_feature = pd.DataFrame(data=[],columns=group_by.columns)\n",
    "\n",
    "for a,b in zip(most_frequent['Input_Features'],most_frequent['Conto']):\n",
    "    last_feature.loc[len(last_feature)] =  {'Input_Features':a,'F_Score':group_by[group_by['Input_Features'] == a]['F_Score'].values[0]*b}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "1        Flow Pkts/s  7.379965\n",
      "0      Flow IAT Mean  6.602293\n",
      "9       Flow IAT Max  3.979795\n",
      "7       Flow IAT Std  3.412502\n",
      "2        Bwd IAT Tot  3.366814\n",
      "6        Fwd IAT Std  3.124727\n",
      "8       Fwd IAT Mean  2.875020\n",
      "4  Init Bwd Win Byts  2.493741\n",
      "5         Fwd Pkts/s  2.252472\n",
      "3  Init Fwd Win Byts  2.063818\n"
     ]
    }
   ],
   "source": [
    "# Facciamo una stampa ordinata\n",
    "\n",
    "print(last_feature.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Pkts/s\n",
      "Flow IAT Mean\n",
      "Flow Pkts/s\n",
      "Flow IAT Max\n",
      "Flow Pkts/s\n",
      "Flow IAT Std\n",
      "Flow Pkts/s\n",
      "Bwd IAT Tot\n",
      "Flow IAT Mean\n",
      "Flow IAT Max\n",
      "Flow IAT Mean\n",
      "Flow IAT Std\n",
      "Flow IAT Mean\n",
      "Bwd IAT Tot\n",
      "Flow IAT Max\n",
      "Flow IAT Std\n",
      "Flow IAT Max\n",
      "Bwd IAT Tot\n",
      "Flow IAT Std\n",
      "Bwd IAT Tot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A questo punto ci interessano solo le prime 5 feature, e tutte le loro possibili combinazioni di due elementi.\n",
    "\n",
    "esito_finale = pd.DataFrame(data=[],columns=['Feature_1','Feature_2'])\n",
    "top_index = []\n",
    "\n",
    "# Qui andiamo a prendere gli indici delle prime 5 features\n",
    "\n",
    "for a in range(0,5):\n",
    "    top_index.append(last_feature.sort_values(by='F_Score',ascending=False).index[a])\n",
    "    \n",
    "\n",
    "# Andiamo a inserire tutte le possibili combinazioni nel dataframe\n",
    "\n",
    "for b in comb:\n",
    "    print(last_feature.loc[top_index[b[0]]]['Input_Features'])\n",
    "    print(last_feature.loc[top_index[b[1]]]['Input_Features'])\n",
    "    esito_finale.loc[len(esito_finale)] =  {\n",
    "        'Feature_1': last_feature.loc[top_index[b[0]]]['Input_Features'],\n",
    "        'Feature_2': last_feature.loc[top_index[b[1]]]['Input_Features']\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature_1      Feature_2\n",
      "0    Flow Pkts/s  Flow IAT Mean\n",
      "1    Flow Pkts/s   Flow IAT Max\n",
      "2    Flow Pkts/s   Flow IAT Std\n",
      "3    Flow Pkts/s    Bwd IAT Tot\n",
      "4  Flow IAT Mean   Flow IAT Max\n",
      "5  Flow IAT Mean   Flow IAT Std\n",
      "6  Flow IAT Mean    Bwd IAT Tot\n",
      "7   Flow IAT Max   Flow IAT Std\n",
      "8   Flow IAT Max    Bwd IAT Tot\n",
      "9   Flow IAT Std    Bwd IAT Tot\n"
     ]
    }
   ],
   "source": [
    "print(esito_finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Flow Pkts/s\n",
      "1    Flow IAT Mean\n",
      "2     Flow IAT Max\n",
      "3     Flow IAT Std\n",
      "4      Bwd IAT Tot\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "top5 = esito_finale.Feature_1.unique()\n",
    "top5 = np.append(top5,esito_finale.Feature_2.unique())\n",
    "top5 = pd.Series(top5)\n",
    "top5 = top5.unique()\n",
    "top5 = pd.Series(top5)\n",
    "print(top5)\n",
    "\n",
    "top5.to_csv('top_feature/'+document+'/top5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "esito_finale.to_csv('top_feature/'+document+'/combinazioni.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
