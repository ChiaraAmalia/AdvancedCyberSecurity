{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie\n",
    "\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili globali\n",
    "\n",
    "mypath = 'dataset'\n",
    "\n",
    "# Mi vado a prendere i path di tutti i file nella cartella dataset\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Mi vado a generare tutte le possibili combinazioni di due elementi da un insieme di 5 elementi\n",
    "\n",
    "\n",
    "comb = list(combinations(range(0,5), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday-02-03-2018_TrafficForML_CICFlowMeter\n"
     ]
    }
   ],
   "source": [
    "# Andiamo a selezionare il file d'interesse\n",
    "\n",
    "document = 'Friday-02-03-2018_TrafficForML_CICFlowMeter'\n",
    "idx = 0\n",
    "\n",
    "for i, j in enumerate(onlyfiles):\n",
    "    if j == document:\n",
    "        idx = i\n",
    "\n",
    "folder = onlyfiles[idx]\n",
    "folder = folder.replace('.csv','')\n",
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a pulire tutti i dataset\n",
    "\n",
    "# Come prima cosa andiamo a leggere le feature dai vari file csv\n",
    "\n",
    "anova = pd.read_csv('top_feature/'+'Friday-23-02-2018_TrafficForML_CICFlowMeter'+\"/anova.csv\")\n",
    "tree = pd.read_csv('top_feature/'+'Friday-23-02-2018_TrafficForML_CICFlowMeter'+\"/ExtraTree.csv\")\n",
    "svm = pd.read_csv('top_feature/'+'Friday-23-02-2018_TrafficForML_CICFlowMeter'+\"/SVM.csv\")\n",
    "rfe = pd.read_csv('top_feature/'+'Friday-23-02-2018_TrafficForML_CICFlowMeter'+\"/RFE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a normalizzare tutti gli score delle feature, in maniera tale da avere valori compresi tra 0 e 1\n",
    "\n",
    "anova['F_Score'] = anova['F_Score']/anova['F_Score'].max()\n",
    "tree['F_Score'] = tree['F_Score']/tree['F_Score'].max()\n",
    "svm['F_Score'] = svm['F_Score']/svm['F_Score'].max()\n",
    "rfe['F_Score'] = rfe['F_Score']/rfe['F_Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Features</th>\n",
       "      <th>F_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotLen Fwd Pkts</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subflow Fwd Byts</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fwd Act Data Pkts</td>\n",
       "      <td>0.716001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pkt Len Min</td>\n",
       "      <td>0.413904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fwd Pkt Len Min</td>\n",
       "      <td>0.381537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fwd Pkt Len Mean</td>\n",
       "      <td>0.193404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fwd Seg Size Avg</td>\n",
       "      <td>0.193404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Idle Std</td>\n",
       "      <td>0.123829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bwd Pkt Len Mean</td>\n",
       "      <td>0.081118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bwd Seg Size Avg</td>\n",
       "      <td>0.081118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Input_Features   F_Score\n",
       "0    TotLen Fwd Pkts  1.000000\n",
       "1   Subflow Fwd Byts  1.000000\n",
       "2  Fwd Act Data Pkts  0.716001\n",
       "3        Pkt Len Min  0.413904\n",
       "4    Fwd Pkt Len Min  0.381537\n",
       "5   Fwd Pkt Len Mean  0.193404\n",
       "6   Fwd Seg Size Avg  0.193404\n",
       "7           Idle Std  0.123829\n",
       "8   Bwd Pkt Len Mean  0.081118\n",
       "9   Bwd Seg Size Avg  0.081118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo una concatenazione dei vari dataframe.\n",
    "# Saranno utilizzati per prendere le feature che si ripetono di più e che hanno i punteggi maggiori\n",
    "\n",
    "total_feature = pd.concat([anova,tree,svm,rfe],ignore_index=True)\n",
    "total_feature_count = pd.concat([anova,tree,svm,rfe],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "5        ECE Flag Cnt      3\n",
      "21  Init Fwd Win Byts      3\n",
      "16    Fwd Pkt Len Std      2\n",
      "2    Bwd Pkt Len Mean      2\n",
      "25   Subflow Fwd Byts      2\n",
      "24       RST Flag Cnt      2\n",
      "23        Pkt Len Min      2\n",
      "7        Flow IAT Max      2\n",
      "19           Idle Std      2\n",
      "1     Bwd Pkt Len Max      2\n",
      "17         Fwd Pkts/s      2\n",
      "0          Active Min      1\n",
      "22        Pkt Len Max      1\n",
      "20  Init Bwd Win Byts      1\n",
      "18   Fwd Seg Size Avg      1\n",
      "13    Fwd Pkt Len Max      1\n",
      "15    Fwd Pkt Len Min      1\n",
      "14   Fwd Pkt Len Mean      1\n",
      "12        Fwd IAT Tot      1\n",
      "11  Fwd Act Data Pkts      1\n",
      "10        Flow Pkts/s      1\n",
      "9        Flow IAT Std      1\n",
      "8        Flow IAT Min      1\n",
      "6       Flow Duration      1\n",
      "4    Bwd Seg Size Avg      1\n",
      "3     Bwd Pkt Len Std      1\n",
      "26    TotLen Fwd Pkts      1\n"
     ]
    }
   ],
   "source": [
    "# Andiamo a eseguire un operazione di group by, con successivo count delle occorrenze dei vari campi\n",
    "\n",
    "total_feature_count = total_feature_count.groupby(['Input_Features']).count().reset_index().sort_values(by='F_Score',ascending=False)\n",
    "\n",
    "# Andiamo a rinominare la colonna F_Score, che adesso contiene i valori di count\n",
    "\n",
    "total_feature_count.rename(columns = {'F_Score':'Conto'}, inplace = True)\n",
    "print(total_feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "5        ECE Flag Cnt      3\n",
      "21  Init Fwd Win Byts      3\n",
      "16    Fwd Pkt Len Std      2\n",
      "2    Bwd Pkt Len Mean      2\n",
      "25   Subflow Fwd Byts      2\n",
      "24       RST Flag Cnt      2\n",
      "23        Pkt Len Min      2\n",
      "7        Flow IAT Max      2\n",
      "19           Idle Std      2\n",
      "1     Bwd Pkt Len Max      2\n"
     ]
    }
   ],
   "source": [
    "# Delle delle feature più frequenti mi interessano le prime dieci\n",
    "\n",
    "most_frequent = total_feature_count[:10]\n",
    "\n",
    "print(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features   F_Score\n",
      "12       ECE Flag Cnt  0.174431\n",
      "26       ECE Flag Cnt  0.510887\n",
      "33       ECE Flag Cnt  1.000000\n",
      "10  Init Fwd Win Byts  1.000000\n",
      "29  Init Fwd Win Byts  0.408599\n",
      "36  Init Fwd Win Byts  1.000000\n",
      "20    Fwd Pkt Len Std  1.000000\n",
      "30    Fwd Pkt Len Std  1.000000\n",
      "8    Bwd Pkt Len Mean  0.081118\n",
      "13   Bwd Pkt Len Mean  0.132329\n",
      "1    Subflow Fwd Byts  1.000000\n",
      "38   Subflow Fwd Byts  1.000000\n",
      "11       RST Flag Cnt  0.180407\n",
      "25       RST Flag Cnt  0.510887\n",
      "3         Pkt Len Min  0.413904\n",
      "27        Pkt Len Min  0.470133\n",
      "14       Flow IAT Max  0.127150\n",
      "34       Flow IAT Max  1.000000\n",
      "7            Idle Std  0.123829\n",
      "28           Idle Std  0.438420\n",
      "21    Bwd Pkt Len Max  0.803214\n",
      "32    Bwd Pkt Len Max  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Ci serve ancora il parametro F_Scores, quindi creiamo un nuovo dataframe con queste righe.\n",
    "# Abbiamo le dieci righe, però, sono ancora presenti le ridondanze che prima avevamo eliminato.\n",
    "\n",
    "test = pd.DataFrame(data=[],columns=total_feature.columns)\n",
    "\n",
    "for a in most_frequent['Input_Features']:\n",
    "    test = pd.concat([test,total_feature[total_feature['Input_Features'] == a]])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una variabile all'interno del quale vado a salvare il groupby del precedente dataframe, solo che in uesto caso\n",
    "# andiamo a sommare i punteggi di F_Scores, invece di contare le occorrenze.\n",
    "\n",
    "group_by = test.groupby(['Input_Features'])['F_Score'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "0    Bwd Pkt Len Max  1.803214\n",
      "1   Bwd Pkt Len Mean  0.213447\n",
      "2       ECE Flag Cnt  1.685318\n",
      "3       Flow IAT Max  1.127150\n",
      "4    Fwd Pkt Len Std  2.000000\n",
      "5           Idle Std  0.562249\n",
      "6  Init Fwd Win Byts  2.408599\n",
      "7        Pkt Len Min  0.884037\n",
      "8       RST Flag Cnt  0.691294\n",
      "9   Subflow Fwd Byts  2.000000\n"
     ]
    }
   ],
   "source": [
    "print(group_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "6  Init Fwd Win Byts  2.408599\n",
      "4    Fwd Pkt Len Std  2.000000\n",
      "9   Subflow Fwd Byts  2.000000\n",
      "0    Bwd Pkt Len Max  1.803214\n",
      "2       ECE Flag Cnt  1.685318\n",
      "3       Flow IAT Max  1.127150\n",
      "7        Pkt Len Min  0.884037\n",
      "8       RST Flag Cnt  0.691294\n",
      "5           Idle Std  0.562249\n",
      "1   Bwd Pkt Len Mean  0.213447\n"
     ]
    }
   ],
   "source": [
    "# Facciamo un ordinamento del dataframe precedente\n",
    "\n",
    "print(group_by.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A questo punto, terminiamo l'operazione andando a moltiplicare la frequenza per la somma dei punteggi delle varie feature.\n",
    "\n",
    "last_feature = pd.DataFrame(data=[],columns=group_by.columns)\n",
    "\n",
    "for a,b in zip(most_frequent['Input_Features'],most_frequent['Conto']):\n",
    "    last_feature.loc[len(last_feature)] =  {'Input_Features':a,'F_Score':group_by[group_by['Input_Features'] == a]['F_Score'].values[0]*b}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "1  Init Fwd Win Byts  7.225796\n",
      "0       ECE Flag Cnt  5.055954\n",
      "2    Fwd Pkt Len Std  4.000000\n",
      "4   Subflow Fwd Byts  4.000000\n",
      "9    Bwd Pkt Len Max  3.606428\n",
      "7       Flow IAT Max  2.254299\n",
      "6        Pkt Len Min  1.768074\n",
      "5       RST Flag Cnt  1.382588\n",
      "8           Idle Std  1.124498\n",
      "3   Bwd Pkt Len Mean  0.426894\n"
     ]
    }
   ],
   "source": [
    "# Facciamo una stampa ordinata\n",
    "\n",
    "print(last_feature.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A questo punto ci interessano solo le prime 5 feature, e tutte le loro possibili combinazioni di due elementi.\n",
    "\n",
    "esito_finale = pd.DataFrame(data=[],columns=['Feature_1','Feature_2'])\n",
    "top_index = []\n",
    "\n",
    "# Qui andiamo a prendere gli indici delle prime 5 features\n",
    "\n",
    "for a in range(0,5):\n",
    "    top_index.append(last_feature.sort_values(by='F_Score',ascending=False).index[a])\n",
    "    \n",
    "# Andiamo a inserire tutte le possibili combinazioni nel dataframe\n",
    "\n",
    "for b in comb:\n",
    "\n",
    "    esito_finale.loc[len(esito_finale)] =  {\n",
    "        'Feature_1': last_feature.loc[top_index[b[0]]]['Input_Features'],\n",
    "        'Feature_2': last_feature.loc[top_index[b[1]]]['Input_Features']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature_1         Feature_2\n",
      "0  Init Fwd Win Byts      ECE Flag Cnt\n",
      "1  Init Fwd Win Byts   Fwd Pkt Len Std\n",
      "2  Init Fwd Win Byts  Subflow Fwd Byts\n",
      "3  Init Fwd Win Byts   Bwd Pkt Len Max\n",
      "4       ECE Flag Cnt   Fwd Pkt Len Std\n",
      "5       ECE Flag Cnt  Subflow Fwd Byts\n",
      "6       ECE Flag Cnt   Bwd Pkt Len Max\n",
      "7    Fwd Pkt Len Std  Subflow Fwd Byts\n",
      "8    Fwd Pkt Len Std   Bwd Pkt Len Max\n",
      "9   Subflow Fwd Byts   Bwd Pkt Len Max\n"
     ]
    }
   ],
   "source": [
    "print(esito_finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo l'esito finale in un file csv\n",
    "\n",
    "esito_finale.to_csv('top_feature/'+folder+'/combinazioni.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
