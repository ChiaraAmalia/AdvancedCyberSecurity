{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad individuare le 5 migliori feature combinado tutti gli algoritmi di feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie\n",
    "\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili globali\n",
    "\n",
    "mypath = 'dataset'\n",
    "\n",
    "# Mi vado a prendere i path di tutti i file nella cartella dataset\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Mi vado a generare tutte le possibili combinazioni di due elementi da un insieme di 5 elementi\n",
    "\n",
    "\n",
    "comb = list(combinations(range(0,5), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = 'Friday-02-03-2018_TrafficForML_CICFlowMeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come prima cosa andiamo a leggere le feature dai vari file csv\n",
    "\n",
    "anova = pd.read_csv('top_feature/'+document+\"/anova.csv\")\n",
    "tree = pd.read_csv('top_feature/'+document+\"/ExtraTree.csv\")\n",
    "svm = pd.read_csv('top_feature/'+document+\"/SVM.csv\")\n",
    "rfe = pd.read_csv('top_feature/'+document+\"/RFE.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a normalizzare tutti gli score delle feature, in maniera tale da avere valori compresi tra 0 e 1\n",
    "\n",
    "anova['F_Score'] = anova['F_Score']/anova['F_Score'].max()\n",
    "tree['F_Score'] = tree['F_Score']/tree['F_Score'].max()\n",
    "svm['F_Score'] = svm['F_Score']/svm['F_Score'].max()\n",
    "rfe['F_Score'] = rfe['F_Score']/rfe['F_Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Features</th>\n",
       "      <th>F_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bwd Pkt Len Max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RST Flag Cnt</td>\n",
       "      <td>0.837338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECE Flag Cnt</td>\n",
       "      <td>0.837328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bwd Pkt Len Mean</td>\n",
       "      <td>0.776309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bwd Seg Size Avg</td>\n",
       "      <td>0.776309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bwd Pkt Len Std</td>\n",
       "      <td>0.722059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fwd Seg Size Min</td>\n",
       "      <td>0.700071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Init Bwd Win Byts</td>\n",
       "      <td>0.640212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pkt Size Avg</td>\n",
       "      <td>0.618322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pkt Len Max</td>\n",
       "      <td>0.561326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Input_Features   F_Score\n",
       "0    Bwd Pkt Len Max  1.000000\n",
       "1       RST Flag Cnt  0.837338\n",
       "2       ECE Flag Cnt  0.837328\n",
       "3   Bwd Pkt Len Mean  0.776309\n",
       "4   Bwd Seg Size Avg  0.776309\n",
       "5    Bwd Pkt Len Std  0.722059\n",
       "6   Fwd Seg Size Min  0.700071\n",
       "7  Init Bwd Win Byts  0.640212\n",
       "8       Pkt Size Avg  0.618322\n",
       "9        Pkt Len Max  0.561326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo una concatenazione dei vari dataframe.\n",
    "# Saranno utilizzati per prendere le feature che si ripetono di più e che hanno i punteggi maggiori\n",
    "\n",
    "total_feature = pd.concat([anova,tree,svm,rfe],ignore_index=True)\n",
    "total_feature_count = pd.concat([anova,tree,svm,rfe],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "15         Fwd Pkts/s      3\n",
      "5        ECE Flag Cnt      3\n",
      "9         Flow Pkts/s      3\n",
      "17  Init Bwd Win Byts      3\n",
      "0        ACK Flag Cnt      2\n",
      "2    Bwd Pkt Len Mean      2\n",
      "22       RST Flag Cnt      2\n",
      "20        Pkt Len Max      2\n",
      "8        Flow IAT Min      2\n",
      "18  Init Fwd Win Byts      2\n",
      "1     Bwd Pkt Len Max      2\n",
      "16   Fwd Seg Size Min      2\n",
      "21       Pkt Size Avg      1\n",
      "19       PSH Flag Cnt      1\n",
      "12       Fwd IAT Mean      1\n",
      "14   Fwd Pkt Len Mean      1\n",
      "13        Fwd IAT Min      1\n",
      "11        Fwd IAT Max      1\n",
      "10     Fwd Header Len      1\n",
      "7       Flow IAT Mean      1\n",
      "6        FIN Flag Cnt      1\n",
      "4    Bwd Seg Size Avg      1\n",
      "3     Bwd Pkt Len Std      1\n",
      "23       URG Flag Cnt      1\n"
     ]
    }
   ],
   "source": [
    "# Andiamo a eseguire un operazione di group by, con successivo count delle occorrenze dei vari campi\n",
    "\n",
    "total_feature_count = total_feature_count.groupby(['Input_Features']).count().reset_index().sort_values(by='F_Score',ascending=False)\n",
    "\n",
    "# Andiamo a rinominare la colonna F_Score, che adesso contiene i valori di count\n",
    "\n",
    "total_feature_count.rename(columns = {'F_Score':'Conto'}, inplace = True)\n",
    "print(total_feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features  Conto\n",
      "15         Fwd Pkts/s      3\n",
      "5        ECE Flag Cnt      3\n",
      "9         Flow Pkts/s      3\n",
      "17  Init Bwd Win Byts      3\n",
      "0        ACK Flag Cnt      2\n",
      "2    Bwd Pkt Len Mean      2\n",
      "22       RST Flag Cnt      2\n",
      "20        Pkt Len Max      2\n",
      "8        Flow IAT Min      2\n",
      "18  Init Fwd Win Byts      2\n"
     ]
    }
   ],
   "source": [
    "# Delle delle feature più frequenti mi interessano le prime dieci\n",
    "\n",
    "most_frequent = total_feature_count[:10]\n",
    "\n",
    "print(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Input_Features   F_Score\n",
      "14         Fwd Pkts/s  0.435594\n",
      "25         Fwd Pkts/s  0.827847\n",
      "35         Fwd Pkts/s  1.000000\n",
      "2        ECE Flag Cnt  0.837328\n",
      "11       ECE Flag Cnt  0.782799\n",
      "28       ECE Flag Cnt  0.744979\n",
      "15        Flow Pkts/s  0.417705\n",
      "24        Flow Pkts/s  0.843071\n",
      "36        Flow Pkts/s  1.000000\n",
      "7   Init Bwd Win Byts  0.640212\n",
      "23  Init Bwd Win Byts  0.914249\n",
      "30  Init Bwd Win Byts  1.000000\n",
      "12       ACK Flag Cnt  0.591686\n",
      "20       ACK Flag Cnt  1.000000\n",
      "3    Bwd Pkt Len Mean  0.776309\n",
      "37   Bwd Pkt Len Mean  1.000000\n",
      "1        RST Flag Cnt  0.837338\n",
      "10       RST Flag Cnt  1.000000\n",
      "9         Pkt Len Max  0.561326\n",
      "16        Pkt Len Max  0.367574\n",
      "18       Flow IAT Min  0.261071\n",
      "33       Flow IAT Min  1.000000\n",
      "13  Init Fwd Win Byts  0.486912\n",
      "31  Init Fwd Win Byts  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Ci serve ancora il parametro F_Scores, quindi creiamo un nuovo dataframe con queste righe.\n",
    "# Abbiamo le dieci righe, però, sono ancora presenti le ridondanze che prima avevamo eliminato.\n",
    "\n",
    "test = pd.DataFrame(data=[],columns=total_feature.columns)\n",
    "\n",
    "for a in most_frequent['Input_Features']:\n",
    "    test = pd.concat([test,total_feature[total_feature['Input_Features'] == a]])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una variabile all'interno del quale vado a salvare il groupby del precedente dataframe, solo che in uesto caso\n",
    "# andiamo a sommare i punteggi di F_Scores, invece di contare le occorrenze.\n",
    "\n",
    "group_by = test.groupby(['Input_Features'])['F_Score'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "0       ACK Flag Cnt  1.591686\n",
      "1   Bwd Pkt Len Mean  1.776309\n",
      "2       ECE Flag Cnt  2.365106\n",
      "3       Flow IAT Min  1.261071\n",
      "4        Flow Pkts/s  2.260776\n",
      "5         Fwd Pkts/s  2.263441\n",
      "6  Init Bwd Win Byts  2.554461\n",
      "7  Init Fwd Win Byts  1.486912\n",
      "8        Pkt Len Max  0.928900\n",
      "9       RST Flag Cnt  1.837338\n"
     ]
    }
   ],
   "source": [
    "print(group_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "6  Init Bwd Win Byts  2.554461\n",
      "2       ECE Flag Cnt  2.365106\n",
      "5         Fwd Pkts/s  2.263441\n",
      "4        Flow Pkts/s  2.260776\n",
      "9       RST Flag Cnt  1.837338\n",
      "1   Bwd Pkt Len Mean  1.776309\n",
      "0       ACK Flag Cnt  1.591686\n",
      "7  Init Fwd Win Byts  1.486912\n",
      "3       Flow IAT Min  1.261071\n",
      "8        Pkt Len Max  0.928900\n"
     ]
    }
   ],
   "source": [
    "# Facciamo un ordinamento del dataframe precedente\n",
    "\n",
    "print(group_by.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A questo punto, terminiamo l'operazione andando a moltiplicare la frequenza per la somma dei punteggi delle varie feature.\n",
    "\n",
    "last_feature = pd.DataFrame(data=[],columns=group_by.columns)\n",
    "\n",
    "for a,b in zip(most_frequent['Input_Features'],most_frequent['Conto']):\n",
    "    last_feature.loc[len(last_feature)] =  {'Input_Features':a,'F_Score':group_by[group_by['Input_Features'] == a]['F_Score'].values[0]*b}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input_Features   F_Score\n",
      "3  Init Bwd Win Byts  7.663383\n",
      "1       ECE Flag Cnt  7.095318\n",
      "0         Fwd Pkts/s  6.790324\n",
      "2        Flow Pkts/s  6.782329\n",
      "6       RST Flag Cnt  3.674675\n",
      "5   Bwd Pkt Len Mean  3.552618\n",
      "4       ACK Flag Cnt  3.183373\n",
      "9  Init Fwd Win Byts  2.973823\n",
      "8       Flow IAT Min  2.522142\n",
      "7        Pkt Len Max  1.857799\n"
     ]
    }
   ],
   "source": [
    "# Facciamo una stampa ordinata\n",
    "\n",
    "print(last_feature.sort_values(by='F_Score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A questo punto ci interessano solo le prime 5 feature, e tutte le loro possibili combinazioni di due elementi.\n",
    "\n",
    "esito_finale = pd.DataFrame(data=[],columns=['Feature_1','Feature_2'])\n",
    "top_index = []\n",
    "\n",
    "# Qui andiamo a prendere gli indici delle prime 5 features\n",
    "\n",
    "for a in range(0,5):\n",
    "    top_index.append(last_feature.sort_values(by='F_Score',ascending=False).index[a])\n",
    "    \n",
    "# Andiamo a inserire tutte le possibili combinazioni nel dataframe\n",
    "\n",
    "for b in comb:\n",
    "\n",
    "    esito_finale.loc[len(esito_finale)] =  {\n",
    "        'Feature_1': last_feature.loc[top_index[b[0]]]['Input_Features'],\n",
    "        'Feature_2': last_feature.loc[top_index[b[1]]]['Input_Features']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature_1     Feature_2\n",
      "0  Init Bwd Win Byts  ECE Flag Cnt\n",
      "1  Init Bwd Win Byts    Fwd Pkts/s\n",
      "2  Init Bwd Win Byts   Flow Pkts/s\n",
      "3  Init Bwd Win Byts  RST Flag Cnt\n",
      "4       ECE Flag Cnt    Fwd Pkts/s\n",
      "5       ECE Flag Cnt   Flow Pkts/s\n",
      "6       ECE Flag Cnt  RST Flag Cnt\n",
      "7         Fwd Pkts/s   Flow Pkts/s\n",
      "8         Fwd Pkts/s  RST Flag Cnt\n",
      "9        Flow Pkts/s  RST Flag Cnt\n"
     ]
    }
   ],
   "source": [
    "print(esito_finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "esito_finale.to_csv('top_feature/'+document+'/combinazioni.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
