{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/Friday-16-02-2018_TrafficForML_CICFlowMeter/scaled_document.pickle', 'rb') as handle:\n",
    "\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prova['test'] = np.random.randint(1, 10, df_prova.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_file='Friday-02-03-2018_TrafficForML_CICFlowMeter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_comb=pd.read_csv('top_feature/'+nome_file+'/combinazioni.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only annual income and spending score\n",
    "from sklearn.cluster import KMeans\n",
    "for index,row in lista_comb.iterrows():\n",
    "    a = pd.DataFrame(data={row[0]:df[row[0]],row[1]:df[row[1]]})\n",
    "    x = a.iloc[:, [0, 1]].values\n",
    "\n",
    "    # let's check the shape of x\n",
    "    print(x.shape)\n",
    "\n",
    "    km = KMeans(n_clusters = 2, init = 'random', max_iter = 100, n_init = 5, random_state = 0)\n",
    "    y_means = km.fit_predict(x)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'magenta', label = 'Benign')\n",
    "    plt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'pink', label = 'Bot')\n",
    "    plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centroid')\n",
    "    plt.title('K Means Clustering', fontsize = 20)\n",
    "    plt.xlabel(row[0])\n",
    "    plt.ylabel(row[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    title = str(row[0])+' - '+str(row[1])\n",
    "    feature_name = title.replace('/','_')\n",
    "    if not os.path.exists('image/'+nome_file+'/cluster_KMeans/'):\n",
    "        os.makedirs('image/'+nome_file+'/cluster_KMeans/')\n",
    "    plt.savefig('image/'+nome_file+'/cluster_KMeans/'+str(feature_name)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "prova = df.values\n",
    "neigh = NearestNeighbors(n_neighbors=5, n_jobs=4, algorithm='ball_tree', leaf_size=5)\n",
    "nbrs = neigh.fit(prova)\n",
    "distances, indices = nbrs.kneighbors(prova)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(distances[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=1, min_samples=6).fit(prova)\n",
    "ymeans = db.labels_\n",
    "ymeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from minisom import MiniSom\n",
    "\n",
    "# Genera dati di esempio\n",
    "X, _ = make_blobs(n_samples=100, n_features=2, centers=4, random_state=0)\n",
    "\n",
    "# Definisci le dimensioni della mappa\n",
    "map_width = 10\n",
    "map_height = 10\n",
    "\n",
    "# Inizializza la SOM\n",
    "som = MiniSom(map_width, map_height, 2, sigma=1.0, learning_rate=0.5)\n",
    "\n",
    "# Inizializza i pesi in modo casuale\n",
    "som.random_weights_init(X)\n",
    "\n",
    "# Addestra la SOM\n",
    "som.train_batch(X, 1000)\n",
    "\n",
    "# Trova il BMU (Best Matching Unit) per ogni campione di input\n",
    "bmu_indexes = np.array([som.winner(x) for x in X])\n",
    "\n",
    "# Stampa i BMU e i relativi vettori di peso\n",
    "for i, (x, bmu) in enumerate(zip(X, bmu_indexes)):\n",
    "    print(f\"Campione {i+1}:\")\n",
    "    print(\"Input:\", x)\n",
    "    print(\"BMU Indice:\", bmu)\n",
    "    print(\"BMU Peso:\", som.weights[bmu[0], bmu[1]])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
