{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAMBIO PATH PER PRENDERE I FILE CSV PER LA CREAZIONE DEL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = os.path.abspath(os.getcwd()) #prendiamo il path in cui si trova il file su cui stiamo lavorando\n",
    "print(path_file)\n",
    "os.chdir(path_file) #cambiamo directory al fine di poter prendere i file csv per la creazione del dataframe\n",
    "data = \"\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = path_file + data\n",
    "print(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(final_path,'*.csv') #lista di tutti gli elementi con estensione csv nella cartella final_path\n",
    "csv_list = glob.glob(data_path) #converte data path in un output Unix-like (ls) (*.csv -> lista di elementi con estensione csv)\n",
    "print(csv_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DATAFRAME CHE CONTERRA' I DATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() #creazione di un dataframe vuoto\n",
    "\n",
    "count = 0\n",
    "# ciclo per scorrere tutti i csv\n",
    "for csv_file in csv_list: # ciclo che scorre i csv nella cartella path\n",
    "    df_csv = pd.read_csv(csv_file) \n",
    "    if count == 3:\n",
    "        first = ['Dst Port', 'Protocol', 'Timestamp','Flow ID','Src IP','Dst IP']\n",
    "    else:\n",
    "        first = ['Dst Port', 'Protocol', 'Timestamp']\n",
    "    \n",
    "    for a in first:\n",
    "        df_csv.drop(columns=a,axis=1,inplace=True)\n",
    "    df = pd.concat([df,df_csv],ignore_index=True)\n",
    "    count = count + 1\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminiamo tutte le feature che hanno un solo valore\n",
    "\n",
    "scarto = []\n",
    "scarto.append([])\n",
    "\n",
    "for a in df.head(0):\n",
    "    \n",
    "    if(df[a].unique().shape[0] == 1):\n",
    "        scarto[-1].append(a)\n",
    "        df.drop(columns=a,axis=1,inplace=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuovo tutte le righe che sono una duplicazione dell'intestazione\n",
    "df = df[df.Label != \"Label\"]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attaccanti_label = df['Label'].unique()\n",
    "print(attaccanti_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sostituisco tutte le label diverse da \"benign\" con \"malign\" per avere un clustering più efficiente\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'Label'] != 'Benign':\n",
    "        df.loc[i, 'Label'] = 'Malign'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attaccanti_label = df['Label'].unique()\n",
    "print(attaccanti_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a sostituire le label con valori interi\n",
    "\n",
    "for b,c in zip(attaccanti_label,range(len(attaccanti_label))):\n",
    "    df = df.replace(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nel documento sono presenti valori infiniti, li andiamo a sostituire con Nan che verranno successivamente rimossi\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Eliminiamo i valori nulli\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a castare tutte le stringhe rimanenti in numeri, in quanto alcuni numeri sono rappresentati come stringhe\n",
    "\n",
    "for label in df.head(0):\n",
    "    if(label != 'Label'):\n",
    "        try:\n",
    "            df[label] = df[label].astype(float)\n",
    "        except:\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco una funzione per normalizzare i valori\n",
    "\n",
    "def normalize(feature:str):\n",
    "    return (df[feature]-df[feature].min())/(df[feature].max()-df[feature].min())\n",
    "\n",
    "\n",
    "# Andiamo a normalizzare i valori per poter usare i vari algoritmi di feature selection\n",
    "\n",
    "scaled_document = df.head(0)\n",
    "\n",
    "for a in df.head(0):\n",
    "    \n",
    "    try:\n",
    "        if df[a].max() != 0 and a != 'Label':\n",
    "            scaled_document[a] = normalize(a)\n",
    "        else:\n",
    "            scaled_document[a] = df[a]\n",
    "    except:\n",
    "\n",
    "        print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mi devo salvare il pickle (fare in questo file)\n",
    "poi riprendere i file dei feature selection per vedere quali sono le 5 feature più importanti (si può fare in un altro file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
