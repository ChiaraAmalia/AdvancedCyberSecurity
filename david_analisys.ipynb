{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAMBIO PATH PER PRENDERE IL FILE CSV PER LA CREAZIONE DEL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = os.path.abspath(os.getcwd()) #prendiamo il path in cui si trova il file su cui stiamo lavorando\n",
    "print(path_file)\n",
    "os.chdir(path_file) #cambiamo directory al fine di poter prendere i file csv per la creazione del dataframe\n",
    "data = \"/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = path_file + data\n",
    "print(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_14 = \"\\Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "#df = pd.read_csv(final_path + file_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(final_path,'*.csv') #lista di tutti gli elementi con estensione csv nella cartella final_path\n",
    "csv_list = glob.glob(data_path) #converte data path in un output Unix-like (ls) (*.csv -> lista di elementi con estensione csv)\n",
    "print(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''grande = \"/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "for csv_file in csv_list:\n",
    "    if csv_file == final_path + grande:\n",
    "        csv_list.remove(csv_file)\n",
    "    \n",
    "print(csv_list)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grande = \"/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "df = pd.DataFrame() #creazione di un dataframe vuoto\n",
    "first = ['Dst Port', 'Protocol', 'Timestamp']\n",
    "first_grande = ['Dst Port', 'Protocol', 'Timestamp','Flow ID','Src IP','Dst IP']\n",
    "\n",
    "# ciclo per scorrere tutti i csv\n",
    "for csv_file in csv_list: # ciclo che scorre i csv nella cartella path\n",
    "    df_csv = pd.read_csv(csv_file) \n",
    "    if csv_file == final_path + grande:\n",
    "        for a in first_grande:\n",
    "            df_csv.drop(columns=a,axis=1,inplace=True)\n",
    "        df = pd.concat([df,df_csv],ignore_index=True)\n",
    "    else:\n",
    "        for a in first:\n",
    "            df_csv.drop(columns=a,axis=1,inplace=True)\n",
    "        df = pd.concat([df,df_csv],ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''remove = ['Fwd Byts/b Avg','Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg','Fwd PSH Flags','FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'URG Flag Cnt', 'ECE Flag Cnt','Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count']\n",
    "\n",
    "for a in remove:\n",
    "    df.drop(columns=a,axis=1,inplace=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminiamo tutte le feature che hanno un solo valore\n",
    "scarto = []\n",
    "scarto.append([])\n",
    "\n",
    "for a in df.head(0):\n",
    "    \n",
    "    if(df[a].unique().shape[0] == 1):\n",
    "        scarto[-1].append(a)\n",
    "        df.drop(columns=a,axis=1,inplace=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GROUP BY RISPETTO ALLE TIPOLOGIE DELL'ATTACCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attaccanti_label = df['Label'].unique()[df['Label'].unique() != 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Label'])['Label'].count()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Label != \"Label\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abbiamo creato un secondo dataframe per plottare i grafici, in modo da rappresentare le diverse tipologie di attacco\n",
    "df_2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a sostituire le label con valori interi\n",
    "\n",
    "for b,c in zip(attaccanti_label,range(len(attaccanti_label))):\n",
    "    df = df.replace(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df = df.replace(\"Benign\", 0)\n",
    "df = df.replace(\"Bot\", 1)\n",
    "df = df.replace(\"Brute Force -Web\", 2)\n",
    "df = df.replace(\"Brute Force -XSS\", 3)\n",
    "df = df.replace(\"DDOS attack-HOIC\", 4)\n",
    "df = df.replace(\"DDOS attack-LOIC-UDP\", 5)\n",
    "df = df.replace(\"DoS attacks-GoldenEye\", 6)\n",
    "df = df.replace(\"DoS attacks-Hulk\", 7)\n",
    "df = df.replace(\"DoS attacks-SlowHTTPTest\", 8)\n",
    "df = df.replace(\"DoS attacks-Slowloris\", 9)\n",
    "df = df.replace(\"FTP-BruteForce\", 10)\n",
    "df = df.replace(\"Infilteration\", 11)\n",
    "df = df.replace(\"SQL Injection\", 12)\n",
    "df = df.replace(\"SSH-Bruteforce\", 13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "display(document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIMOZIONE RIGHE CON CAMPI NULLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in df.head(0):\n",
    "    if(df[a].isna().sum() > 0):\n",
    "        print(df[a].isna().sum())\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_2.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andiamo a castare tutte le stringhe rimanenti in numeri, in quanto alcuni numeri sono rappresentati come stringhe\n",
    "\n",
    "for label in df.head(0):\n",
    "    if(label != 'Label'):\n",
    "        try:\n",
    "            df[label] = df[label].astype(float)\n",
    "            df_2[label] = df_2[label].astype(float)\n",
    "        except:\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_2.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.isna().any(axis=1)]\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZZAZIONE DEI VALORI PER APPLICAZIONE ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco una funzione per normalizzare i valori\n",
    "\n",
    "def normalize(feature:str):\n",
    "    #return (document[feature]-document[feature].mean())/np.std(document[feature])\n",
    "    #return document[feature]/document[feature].max()\n",
    "    return (df[feature]-df[feature].min())/(df[feature].max()-df[feature].min())\n",
    "\n",
    "def normalize_plot(feature:str):\n",
    "    #return (document_plot[feature]-document_plot[feature].mean())/np.std(document_plot[feature])\n",
    "    #return document_plot[feature]/document_plot[feature].max()\n",
    "    return (df_2[feature]-df_2[feature].min())/(df_2[feature].max()-df_2[feature].min())\n",
    "\n",
    "\n",
    "# Andiamo a normalizzare i valori per poter usare i vari algoritmi di feature selection\n",
    "\n",
    "scaled_document = df.head(0)\n",
    "scaled_document_plot = df_2.head(0)\n",
    "\n",
    "for a in df.head(0):\n",
    "    \n",
    "    try:\n",
    "        if df[a].max() != 0 and a != 'Label':\n",
    "            scaled_document[a] = normalize(a)\n",
    "            scaled_document_plot[a] = normalize_plot(a)\n",
    "        else:\n",
    "            scaled_document[a] = df[a]\n",
    "            scaled_document_plot[a] = df_2[a]\n",
    "    except:\n",
    "\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scaled_document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIMOZIONE RIGHE CON CAMPI NULLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = scaled_document[scaled_document.isna().any(axis=1)]\n",
    "display(df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selezione feature pi√π importanti (mediante ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif, f_regression\n",
    "fvalue_Best = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = fvalue_Best.fit(x, y)\n",
    "print(fit)\n",
    "print(fvalue_Best.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_score = pd.DataFrame(fit.scores_)\n",
    "features = pd.DataFrame(x.columns)\n",
    "feature_score = pd.concat([features,features_score],axis=1)\n",
    "# Assigning column names\n",
    "feature_score.columns = [\"Input_Features\",\"F_Score\"]\n",
    "print(feature_score.nlargest(10,columns=\"F_Score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione di una lista in cui andiamo a mettere le feature che non sono state selezionate dal metodo ANOVA\n",
    "i=0\n",
    "index_false=[]\n",
    "for el in list(fvalue_Best.get_support()):\n",
    "    if not el:\n",
    "        index_false.append(i)\n",
    "    i=i+1\n",
    "print(index_false)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIMOZIONE DELLE FEATURE NON SELEZIONATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop(x.columns[index_false],axis = 1)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT DELLE COMBINAZIONI TRA FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "comb = list(combinations(x.head(0), 2))\n",
    "colors = { 'FTP-BruteForce':'orange', 'SSH-Bruteforce':'black','Benign':'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''scaled['Label'] = scaled['Label'].replace(0, \"Benign\")\n",
    "scaled['Label'] = scaled['Label'].replace(1, \"FTP-BruteForce\")\n",
    "scaled['Label'] = scaled['Label'].replace(2, \"SSH-Bruteforce\")\n",
    "display(scaled)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "for a in comb:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(scaled_2[a[0]],scaled_2[a[1]],c=scaled_2['Label'].map(colors),alpha=.1)\n",
    "    handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=v, label=k, markersize=8) for k, v in colors.items()]\n",
    "    plt.legend(title='color', handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(str(a[0])+'-'+str(a[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
