{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_scoreimport pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_file='Friday-02-03-2018_TrafficForML_CICFlowMeter'\n",
    "\n",
    "with open('pickle/'+nome_file+'/scaled_document.pickle', 'rb') as handle:\n",
    "\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = 'Init Bwd Win Byts'\n",
    "feature_2 = 'Fwd Pkts/s'\n",
    "\n",
    "\n",
    "df = df[[feature_1, feature_2,'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = df[df.Label == 1]\n",
    "benign = df[df.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([bot, benign.sample(len(bot))])\n",
    "x = balanced_d.iloc[:,:-1]\n",
    "y = balanced_d.iloc[:,-1:]\n",
    "balanced_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo il clustering\n",
    "\n",
    "n_clusters = len(balanced_d['Label'].unique())  # numero di cluster\n",
    "\n",
    "y_pred = KMeans(n_clusters=n_clusters).fit_predict(x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = x[y_pred == i]\n",
    "    cluster_classes = y[y_pred == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dei risultati\n",
    "plt.scatter(x[feature_1], x[feature_2], c=y['Label'])\n",
    "plt.title(\"Optimal Number of Clusters\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "axs.scatter(x[feature_1], x[feature_2], c=y_pred)\n",
    "axs.set_title(\"Mixture of Gaussian Blobs\")\n",
    "\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)\n",
    "        \n",
    "    axs.text(\n",
    "        np.mean(x[feature_1][y_pred == i]), np.mean(x[feature_2][y_pred == i]),\n",
    "        f\"Cluster {i}: Class {cluster_class_mapping[i]}\",\n",
    "        fontsize=12, fontweight='bold', color='red', ha='center', va='center'\n",
    "    )\n",
    "\n",
    "plt.suptitle(\"Ground truth clusters\").set_y(0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_pred))\n",
    "    if y_pred[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_pred[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_x = balanced_d.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "prova = bal_x.values\n",
    "neigh = NearestNeighbors(n_neighbors=5, n_jobs=4, algorithm='ball_tree', leaf_size=5)\n",
    "nbrs = neigh.fit(prova)\n",
    "distances, indices = nbrs.kneighbors(prova)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(distances[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=1, min_samples=6).fit(prova)\n",
    "ymeans = db.labels_\n",
    "ymeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from minisom import MiniSom\n",
    "\n",
    "# Definisci le dimensioni della mappa\n",
    "map_width = 10\n",
    "map_height = 10\n",
    "\n",
    "# Inizializza la SOM\n",
    "som = MiniSom(map_width, map_height, 2, sigma=1.0, learning_rate=0.5)\n",
    "\n",
    "# Inizializza i pesi in modo casuale\n",
    "som.random_weights_init(bal_x)\n",
    "\n",
    "# Addestra la SOM\n",
    "som.train_batch(bal_x, 1000)\n",
    "\n",
    "# Trova il BMU (Best Matching Unit) per ogni campione di input\n",
    "bmu_indexes = np.array([som.winner(x) for x in bal_x])\n",
    "\n",
    "# Stampa i BMU e i relativi vettori di peso\n",
    "for i, (x, bmu) in enumerate(zip(bal_x, bmu_indexes)):\n",
    "    print(f\"Campione {i+1}:\")\n",
    "    print(\"Input:\", x)\n",
    "    print(\"BMU Indice:\", bmu)\n",
    "    print(\"BMU Peso:\", som.weights[bmu[0], bmu[1]])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
