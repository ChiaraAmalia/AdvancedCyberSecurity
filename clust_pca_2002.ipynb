{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In questo file andiamo ad applicare algoritmi di clustering dopo aver eliminato eventuali duplicati ed aver ridotto le dimensioni del dataset con undersampling. Prima di applicare gli algoritmi di clustering, applichiamo la pca che ci permette di selezionare le feature più rilevanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib.lines import Line2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_file='Thuesday-20-02-2018_TrafficForML_CICFlowMeter'\n",
    "\n",
    "with open('pickle/'+nome_file+'/scaled_document.pickle', 'rb') as handle:\n",
    "\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminazione duplicati\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona una frazione casuale delle righe in base a una colonna specifica\n",
    "# Selezioniamo il 50% delle righe\n",
    "\n",
    "colonna_interessata = 'Label'\n",
    "frazione_da_selezionare = 0.5  # Ad esempio, seleziona il 50% delle righe\n",
    "\n",
    "\n",
    "df = df.groupby(colonna_interessata).apply(lambda x: x.sample(frac=frazione_da_selezionare, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contiamo il numero di feature per label\n",
    "\n",
    "df_prova = df.groupby(['Label'])['Label'].count()\n",
    "\n",
    "df_prova=df_prova.to_frame()\n",
    "print(df_prova)\n",
    "df_prova.set_index('Label')\n",
    "df_prova=df_prova.rename(columns={'Label':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo un array in cui andiamo a mettere le 5 feature più importanti per filtrare poi il dataframe\n",
    "\n",
    "import csv\n",
    "\n",
    "results = []\n",
    "with open('top_feature/'+ nome_file +'/top5.csv', newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append(row[0])\n",
    "\n",
    "results.pop(0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otteniamo il dataframe con solo le 5 feature più importanti\n",
    "\n",
    "df_filtrato = pd.DataFrame()\n",
    "for a in df.head(0):\n",
    "    if a in results:\n",
    "        df_filtrato[a] = df[a]\n",
    "\n",
    "df_filtrato['Label'] = df['Label']\n",
    "display(df_filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = df_filtrato[df_filtrato.Label == 1]\n",
    "benign = df_filtrato[df_filtrato.Label == 0]\n",
    "\n",
    "print(\"Benign: \", len(benign), \"Bot: \", len(bot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilanciamento del dataset\n",
    "balanced_d = pd.concat([bot, benign.sample(len(bot))])\n",
    "bal_x = balanced_d.iloc[:,:-1]\n",
    "bal_y = balanced_d.iloc[:,-1:]\n",
    "balanced_d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applicazione della PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver=\"auto\").fit(bal_x)\n",
    "pca_x = pca.transform(bal_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(balanced_d['Label'].unique())  # numero di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applicazione del kmeans\n",
    "km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "y_pred = km.fit_predict(pca_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = pca_x[y_pred == i]\n",
    "    cluster_classes = bal_y[y_pred == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "\n",
    "# associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_pred))\n",
    "    if y_pred[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_pred[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dei risultati\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster of PCAs K-means', fontsize = 30)\n",
    "\n",
    "plt.scatter(pca_x[y_pred == 0, 0], pca_x[y_pred == 0, 1], s = 100, c = 'purple', label = \"Benign\")\n",
    "plt.scatter(pca_x[y_pred == 1, 0], pca_x[y_pred == 1, 1], s = 100, c = 'yellow', label = \"Bot\")\n",
    "\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "title = \"KMeans_PCA\"\n",
    "if not os.path.exists('image/'+nome_file+'/clustering_pca/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering_pca/')\n",
    "plt.savefig('image/'+nome_file+'/clustering_pca/'+ title +'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_kmeans = str(accuracy_score(y_pred,bal_y))\n",
    "precision_kmeans = str(precision_score(y_pred,bal_y))\n",
    "recall_kmeans = str(recall_score(y_pred,bal_y))\n",
    "\n",
    "# accuratezza kmeans\n",
    "print(\"accuratezza \" + accuracy_kmeans)\n",
    "# precision kmeans\n",
    "print(\"precision \" + precision_kmeans)\n",
    "# recall kemans\n",
    "print(\"recall \" + recall_kmeans)\n",
    "\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_kmeans,precision_kmeans,recall_kmeans]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering_pca/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering_pca/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering_pca'+'/metriche_kmeans_pca.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering gerarchico\n",
    "\n",
    "hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
    "y_hc = hc.fit_predict(pca_x)\n",
    "\n",
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = pca_x[y_hc == i]\n",
    "    cluster_classes = bal_y[y_hc == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_hc))\n",
    "    if y_hc[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_hc[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(pca_x[y_hc == 0, 0], pca_x[y_hc == 0, 1], s = 100, c = 'purple', label = \"Benign\")\n",
    "plt.scatter(pca_x[y_hc == 1, 0], pca_x[y_hc == 1, 1], s = 100, c = 'yellow', label = \"Bot\")\n",
    "\n",
    "plt.title('Hierarchial Clustering', fontsize = 20)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "title = (\"Clust_gerarchico_PCA\")\n",
    "if not os.path.exists('image/'+nome_file+'/clustering_pca/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering_pca/')\n",
    "plt.savefig('image/'+nome_file+'/clustering_pca/'+ title +'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gerarchico = str(accuracy_score(y_hc,bal_y))\n",
    "precision_gerarchico = str(precision_score(y_hc,bal_y))\n",
    "recall_gerarchico = str(recall_score(y_hc,bal_y))\n",
    "\n",
    "# accuratezza gerarchico\n",
    "print(\"accuratezza\" + accuracy_gerarchico)\n",
    "# precision gerarchico\n",
    "print(\"precision\" + precision_gerarchico)\n",
    "# recall gerarchico\n",
    "print(\"recall\" + recall_gerarchico)\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_gerarchico,precision_gerarchico,recall_gerarchico]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering_pca/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering_pca/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering_pca'+'/metriche_gerarchico_PCA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individuazione eps\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(pca_x)\n",
    "distances, indices = nbrs.kneighbors(pca_x)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(distances[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applicazione DBSCAN\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.01, min_samples=6).fit(pca_x)\n",
    "y_scan = db.labels_\n",
    "y_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associazione del cluster i-esimo con la classe i-esima\n",
    "cluster_class_mapping = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_samples = pca_x[y_scan == i]\n",
    "    cluster_classes = bal_y[y_scan == i]\n",
    "    unique_classes, class_counts = np.unique(cluster_classes, return_counts=True)\n",
    "    dominant_class = unique_classes[np.argmax(class_counts)]\n",
    "    cluster_class_mapping[i] = dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = pd.DataFrame(data=[],columns=['num_cluster','num_class'])\n",
    "\n",
    "# Stampiamo l'associazione del cluster con la classe\n",
    "for i in range(n_clusters):\n",
    "    if(i != cluster_class_mapping[i]):\n",
    "        new_row = pd.Series({'num_cluster': i, 'num_class': cluster_class_mapping[i]})\n",
    "        difference = pd.concat([difference,new_row.to_frame().T],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se il numero del cluster e la classe non coincidono, andiamo ad effettuare uno switch\n",
    "\n",
    "indici = []\n",
    "\n",
    "for a in difference['num_cluster']:\n",
    "    indici.append([\n",
    "    index for index in range(len(y_scan))\n",
    "    if y_scan[index] == a\n",
    "])\n",
    "\n",
    "for ind,true_value in zip(indici,difference['num_class']):\n",
    "    for a in ind:\n",
    "        y_scan[a] = true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Cluster of PCAs', fontsize = 30)\n",
    "\n",
    "plt.scatter(pca_x[y_scan == -1, 0], pca_x[y_scan == -1, 1], s = 100, c = 'black', label = \"noise\")\n",
    "plt.scatter(pca_x[y_scan == 0, 0], pca_x[y_scan == 0, 1], s = 100, c = 'red', label = \"Benign\")\n",
    "plt.scatter(pca_x[y_scan == 1, 0], pca_x[y_scan == 1, 1], s = 100, c = 'blue', label = \"Bot\")\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "title = (\"DB_Scan_PCA\")\n",
    "feature_name = title.replace('/','_')\n",
    "if not os.path.exists('image/'+nome_file+'/clustering_pca/'):\n",
    "    os.makedirs('image/'+nome_file+'/clustering_pca/')\n",
    "plt.savefig('image/'+nome_file+'/clustering_pca/'+ title +'.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dbscan = str(accuracy_score(y_scan,bal_y))\n",
    "precision_dbscan = str(precision_score(y_scan,bal_y,average='weighted'))\n",
    "recall_dbscan = str(recall_score(y_scan,bal_y,average='weighted'))\n",
    "\n",
    "# accuratezza dbscan\n",
    "print(\"accuratezza\" + accuracy_dbscan)\n",
    "# precision dbscan\n",
    "print(\"precision\" + precision_dbscan)\n",
    "# recall dbscan\n",
    "print(\"recall\" + recall_dbscan)\n",
    "\n",
    "metriche = pd.DataFrame({\n",
    "    'metriche': [\"accuracy\",\"precision\",\"recall\"],\n",
    "    'valori': [accuracy_dbscan,precision_dbscan,recall_dbscan]\n",
    "})\n",
    "\n",
    "if not os.path.exists('metriche/'+nome_file +'/clustering_pca/'):\n",
    "    os.makedirs('metriche/'+nome_file +'/clustering_pca/')\n",
    "\n",
    "metriche.to_csv('metriche/'+nome_file +'/clustering_pca'+'/metriche_dbscan_PCA.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
